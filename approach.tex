
\section{Experimental Approach}
\label{sec:approach}

\subsection{APEI Error Injection}
To develop a detailed understanding of the cost of recovering from correctable 
errors, we collected empirical data using ACPI Platform Error Interfaces~(APEI) Error 
Injection, \emph{see} \refsec{sec:results:dram_correctable}.  APEI is part of the 
Advanced Configuration and Power Interface (ACPI).  ACPI is a standard that defines how 
operating systems interact with the hardware components that comprise the systems on 
which they run.  APEI defines an interface by which the operating system can be notified 
of errors.  The APEI also provides a mechanism for injecting hardware errors: the error 
injection table~(EINJ).

%we use the error injection table (EINJ) support provided as part
%these impacts we need a method of injecting these errors in a system to measure
%the costs.  A number of methods exist to inject these types of errors on a
%running system: from hardware-specific DRAM daughter cards that synthetically
%flip memory cells within the DIMM device to methods that stress the memory
%system in an effort to induce failures. 

%In this work, we use the error injection table (EINJ) support provided as part
%of the Advanced Configuration and Power Interface (ACPI)
%specification~\cite{ACPISpec}.  

EINJ provides a platform-independent interface that enables the operating system to
inject hardware errors to the platform without requiring platform-specific software 
support. The primary objective of this mechanism is to validate operating system 
Reliability, Availability, and Serviceability~(RAS) features.  The ACPI specification 
defines several error types for EINJ.  The supported errors are summarized in \Cref{tab:einj}.  
EINJ is not supported on every platform; it requires support from the host processor, 
OS, and firmware/BIOS.  Moreover, platforms that support EINJ may not support all 
possible error types.  For example, our test platform supports only the \emph{Memory Correctable} 
and \emph{Memory Uncorrectable} error types.

\begin{table}
\centering
\begin{tabular}{ c l }
\toprule
Error Type Value & Error Description \\
\midrule
 0x00000001 & Processor Correctable\\
 0x00000002 & Processor Uncorrectable non-fatal \\
 0x00000004 & Processor Uncorrectable fatal \\
        {\bf{0x00000008}} & {\bf{Memory Correctable}} \\
 0x00000010 & Memory Uncorrectable non-fatal \\
 0x00000020 & Memory Uncorrectable fatal \\
 0x00000040 & PCI Express Correctable \\
 0x00000080 & PCI Express Uncorrectable fatal \\
 0x00000100 & PCI Express Uncorrectable non-fatal \\
 0x00000200 & Platform Correctable \\
 0x00000400 & Platform Uncorrectable non-fatal \\
 0x00000800 & Platform Uncorrectable fatal \\
\bottomrule
\end{tabular}
\vspace{.6em}
\caption{
        Available error types defined in ACPI specification.  The highlighted value
        (\emph{Memory Correctable}) was to collect the data presented in this paper.
}
\label{tab:einj}
\end{table}

%On our test platform, only \emph{Memory
%Correctable and memory uncorrectable error types are supported.  
\sll{KBF: please make sure that I've got this right.}\\
Using the EINJ table to inject errors on Linux-based systems is accomplished by writing to virtual 
files in the sysfs.\footnote{All of the relevant virtual files are in the \texttt{/sys/kernel/debug/apei/einj}
directory.  Additional information about Linux EINJ support, including a simple example of injecting an
error, is available in the Linux kernel documentation, \emph{see} \cite{einj_web}.} Using this interface, 
the user can specify the error type and target memory address, and trigger the injection of the error.

\subsection{Memory Failure Logging}

\kbf{The following paragraph is nearly identical to parallel submission,
change}

DRAM on typical modern systems is protected by an error-correcting
codes~(ECC).  When the memory controller detects a memory error, it attempts to
use the ECC to correct the error.  If it is able to correct the error, the
error is recorded as a \emph{correctable error}~(CE).  If it is unable to
correct the error, the error is recorded as a \emph{detected, uncorrectable
error}~(DUE).  On x86-based processors, correctable errors are recorded in 
registers provided by the x86 Machine Check Architecture~(MCA)~\cite{AMD,IntelGuide}.  
These registers are polled periodically and their contents are used to record
detailed information about the occurrence of the error is written to the console log.
This information includes the physical address where the error occurred and ECC
syndrome data that describes the cause of the error.  Decoding the recorded
information about each error allows us to identify the physical location of
each logged error, but this decoding process takes time, perturbing application
performance.

For correctable errors, there are two types of processor notification: software-based 
and firmware-based.  In the case of software-based notification, a Corrected Machine Check Interrupt
(CMCI)~\cite{IntelGuide,Gottscho:2017:Measuring} is generated which records
the DRAM error and the time of its occurrence.  However, it may be difficult
to determine the precise DRAM location of an error because of complexities related
to memory organization~\cite{Gottscho:2017:Measuring}.  As a result, mitigating
errors with memory page retirement~\cite{Tang:2006:Assessment} may not always
be possible with CMCI-based reporting.  With firmware-based notification, the
information recorded when the error occurs includes the physical address and the
specific DRAM device where the error occurred.  Firmware-based notification relies on the
Enhanced Machine Check Architecture (EMCA)~\cite{MCAEnhancements}.  While this
method allows for precise identification of the source of the error, it is very
expensive.  It requires the system to enter System Management Mode~(SMM) which halts
all forward progress on \emph{all} cores of the processor while the memory configuration 
information is assembled and passed to system software~\cite{Gottscho:2017:Measuring}. 

To measure the system impacts of the memory decoding and logging overheads, we
use the \selfish~\cite{Hoefler:2010:Characterizing} system noise measurement
microbenchmark. \selfish tracks the periods of time (\emph{detours}) when the CPU is
taken from the application to perform system tasks.  It detects detours by continuously reading 
the processor timestamp counter (TSC)~\cite{IntelGuide}.  When the counter interval exceeds a 
user-defined threshold,~\footnote{For the data presented in this section, we used 150 nanoseconds} 
the time and duration of this detour is recorded.  By running \selfish while we inject
errors using EINJ we can measure the time required to recover from a correctable error.

\subsection{Simulating Correctable Overheads}

In general, the communication structure of Message Passing Interface (MPI)
programs cannot be determined offline because message matches cannot be
established statically~\cite{bronevetsky2009communication}.  This makes
modeling application performance analytically challenging even if all
parameters of the application (e.g., the complete communication structure and
all relative inter-process timings) are known.  We therefore use a validated
discrete-event simulation framework to evaluate the impact of local
correctable error mitigation activities on the performance of real applications.
%for real applications via their message traces.

Our simulation-based approach models correctable error mitigation activities as
CPU detours: periods of time during which application progress is blocked correctable
error recovery.  This approach allows a level of
fidelity and control not always possible in implementation-based approaches. It
also allows us to examine simulated systems much larger than those generally
available.

Our simulation framework is based on the freely available
\LogGOPSim~\cite{Hoefler:2010:LogGOPSim} and the tool chain described by Levy et
al.~\cite{Levy2013UsingSimulation}.  \LogGOPSim uses the LogGOPS model, an
extension of the well-known LogP model~\cite{Culler:1993:LogP}, to account for
the temporal cost of communication events.  An application's communication
events are generated from traces of the application's execution.  These traces
contain the sequence of MPI operations invoked by each application process.
\LogGOPSim uses these traces to reproduce all communication dependencies,
including indirect dependencies between processes which do not communicate
directly.

\LogGOPSim can also extrapolate traces from small application runs; a trace
collected by running the application with $p$ processes can be extrapolated to
simulate performance of the application running with $k\cdot p$ processes. The
extrapolation produces exact communication patterns for MPI collective
operations and approximates point-to-point
communications~\cite{Hoefler:2010:LogGOPSim}.  The validation of \LogGOPSim and
its trace extrapolation features have been documented
previously~\cite{Hoefler:2010:LogGOPSim}, along with the simulators ability to
accurately predict application performance in the presence of performance
perturbations~\cite{Ferreira:2014:Understanding,Levy2013UsingSimulation,Hoefler:2010:Characterizing}

\begin{table}
\centering
\begin{tabular}{ l c }
\toprule
LogGOPS parameter & Cray XC40 \\
\midrule
\textcolor{red}{L}atency                & 1.8$\mu s$ \\
\textcolor{red}{o}verhead per message   & 12.4$\mu s$ \\
\textcolor{red}{g}ap per message        & 2.6$\mu s$  \\
\textcolor{red}{G}ap per byte           & 1$ns$     \\
\textcolor{red}{O}verhead per byte      & 0$ns$     \\
\textcolor{red}{S}: rendezvous threshold& 65,536 bytes \\
\bottomrule
\end{tabular}
\vspace{.6em}
\caption{
  LogGOPS parameters used in our study which roughly correspond to a Cray
  XC40 architectures.
}
\label{tab:logp}
\end{table}

\subsection{Simulation Setup and Repeatability}

To generate the data presented in this paper, we collected execution traces for
128 process (125 process for MICL) runs for each of the workloads described in 
\Cref{tab:app_desc} system.  We used these traces~\footnote{All traces from non-export
controlled workloads can found online, details in \Cref{sec:appendix}} to simulate
the execution of the application when we introduce correctable errors.  We configured 
\LogGOPSim to use the network parameters listed in \Cref{tab:logp}.  These values 
were collected on a Cray XC40 system.  \sll{Do we have more details?  Apps?  Can we cite 
something and not put it in the first person?}  We then verified that the simulator accurately 
reproduces (within 6\%) the execution time on the respective system.

We model correctable errors using an extension of the OS noise injection functionality provided
by \LogGOPSim.  Our extension programmatically injects detours that represent correctable errors.
The timing of the correctable error is determined statistically using random numbers drawn from 
an exponential distribution.  The mean of the distribution (i.e., the MTBF of correctable errors)
is based on data regarding the frequency of correctable errors in existing publications, 
\emph{see e.g.},~\cite{Li10,Hwang12,Sridharan13,Bautista-Gomez:2016:Unprotected}.
The duration of the detour is determined by the amount of time required 
to recover from a correctable error.   For the experiments in this paper, we rely on empirical results 
described in this paper (\emph{see} \refsec{sec:results:dram_correctable}) and data published 
elsewhere~\cite{Gottscho:2017:Measuring} for these values.  
Application processes are delayed appropriately when a simulated correctable error occurs.
Delays that occur on one application process have the potential to propagate along
communication dependencies and introduce delays in other processes, \emph{cf.} \Cref{fig:propagation}.

We examine the performance of seven HPC workloads.  These workloads,
described in \Cref{tab:app_desc}, include three important DOE production
applications (LAMMPS, CTH, and SPARC), an important HPC benchmark (HPCG), a
proxy application (LULESH) from the Department of Energy's Exascale Co-Design
Center for Materials in Extreme Environments~(ExMatEx), a scientific code used
to study the behavior of subatomic particles~(MILC), and a
mini-application~(miniFE) from Sandia's Mantevo suite.  This diverse set of
workloads captures a wide range of computational methods and application
behaviors.  It additionally captures a significant cross-section of the
scalable, high-performance applications that are run on current extreme-scale
systems as well as workloads that represent the computational patterns that are
expected to be run on future systems. 

%%% removing as we are not talking about microbecnhmarks ...yet
%Lastly, we also use a number of MPI
%collective microbenchnarks to examine collective algorithm impacts.  The
%pseudocode for these microbenchmarks can be found in \Cref{alg:microbenchmark}.

\newcommand{\appDescWidth}{10.5cm}

\begin{table*}[ht!]
\centering
\begin{tabular}{@{}lc@{}}
\toprule
Application & Description \tabularnewline
\midrule
% NOTE: SNAP is not part of the current LAMMPS distribution
%LAMMPS & \parbox{\appDescWidth}{Large-scale Atomic/Molecular Massively Parallel Simulator (LAMMPS).
        LAMMPS & \parbox{\appDescWidth}{\tiny{A classical molecular dynamics simulator from Sandia National  
                                Laboratories~\cite{Plimpton:1995:Fast, LAMMPS_web}.  The data presented in                           
                                this paper are from experiments that use the Lennard-Jones (LAMMPS-lj)                               
                                potential that is included with the LAMMPS distribution.}}\\
  & \\                          
%LULESH & \parbox{\appDescWidth}{Livermore Unstructured Lagrangian Explicit Shock Hydrodynamics (LULESH).  
        LULESH & \parbox{\appDescWidth}{\tiny{A proxy application from the Department of Energy Exascale Co-Design Center
                                for Materials in Extreme Environments (ExMatEx).  LULESH approximates the
                                hydrodynamics equations discretely by partitioning the spatial problem domain
                                into a collection of volumetric elements defined by a
                                 mesh~\cite{LULESH_web}.}}\\
  & \\
        HPCG & \parbox{\appDescWidth}{\tiny{A benchmark that generates and solves a synthetic 3D sparse linear system using
                              a local symmetric Gauss-Seidel preconditioned conjugate gradient
                              method~\cite{HPCG_web}.}}\\
  & \\
        CTH & \parbox{\appDescWidth}{\tiny{A multi-material, large deformation, strong shock wave, solid mechanics
                             code~\cite{McGlaun:1990:CTH, Hertel:93:CTH} developed at Sandia National 
                             Laboratories.  The data presented in this paper are from experiments that use
                             an input that describes the simulation of the detonation of a conical explosive
                             charge (CTH-st).}}\\
  & \\
        MILC & \parbox{\appDescWidth}{\tiny{A large scale numerical simulation to study quantum chromodynamics~(QCD), the theory
                              of the strong interactions of subatomic physics~\cite{MILC_web}.}}\\
  & \\
        miniFE & \parbox{\appDescWidth}{\tiny{A proxy application that captures the key behaviors of unstructured implicit
                                finite element codes~\cite{Heroux09Mantevo}.}}\\
  & \\
        SPARC & \parbox{\appDescWidth}{\tiny{SPARC~\cite{Howard:2017:Sparc} is a next-generation compressible
        computational fluid dynamics (CFD) code being developed by Sandia National Laboratories
        as part of the NNSA's Advanced Technology Development and Mitigation (ATDM) subprogram.
        SPARC solves the Navier-Stokes and Reynolds-Averaged Navier-Stokes (RANS turbulence models)
        equations on structured and unstructured grids and is targeted towards the transonic flow
        regime to support gravity bomb analyses and the hypersonic flow regime to analyze re-entry
        vehicle analyses. In this work, the ``Generic Reentry Vehicle'' (GRV) input problem was
        used.}}\\

\bottomrule
\end{tabular}
\caption{Descriptions of the workloads used in evaluation.}
\label{tab:app_desc}
\end{table*}

%\begin{figure}[ht!]
%\centering
%%\begin{minipage}[t]{0.90\textwidth}
%\begin{algorithm}[H]
%\caption*{\textbf{Collective operation microbenchmark}}\label{alg:collectives}
%\begin{algorithmic}
%%\State{interval\_duration $\in \lbrace 50ms, 500ms, 5s, 50s\rbrace$}
%        \State{collective\_operation $\in \lbrace$ \texttt{Stencil}\\
%                                          \hspace{2.35cm}\MPIAllreduce, \MPIAlltoall, \\ 
%                                          \hspace{2.35cm}\MPIBcast, \MPIReduce$\rbrace$}
%\State
%\Procedure{collective\_micro}{collective\_operation}
%\ForAll{intervals}
%    \State \emph{execute} collective\_operation
%    \State \emph{sleep} $100ms$
%\EndFor
%\EndProcedure
%\end{algorithmic}
%\end{algorithm}
%%\end{minipage}
%        \captionof{algorithm}{Pseudocode of collective operation microbenchmark.
%        \kbf{Modify to match data}}
%\label{alg:microbenchmark}
%\end{figure}

\subsection{Simulated Correctable Error Rates}

\kbf{Add a discussion and justification here for rates we use} 

\kbf{Median might be a better value in the table below as the distribution is
skewed (errors coming from lots of "noisy" nodes), but that is more difficult
to determine}

\begin{table*} 
        \centering 
        \begin{tabular}{ l c c c c } 
         \toprule
                System & CEs / node / year & GiB / node & CEs / GiB / year & $MTBCE_{node}$ (hours)\\
         \midrule
                Schroeder et al~\cite{Schroeder:09:dram}  & 22,696 & 1--4 & 11,384 & 0.38\\
                Facebook~\cite{meza:2015:revisiting} & 5,964 & 2--24 & 460
                (median 108)& 1.47\\ % median 108 CEs/ node / year
%               Blue Waters~\cite{bluewaters} & 38.94 & 64 & 0.61 & 227.2 \\ %
                %1.04PB, 32Ki nodes
                Cielo~\cite{levy:2018:lessons} & 26.35 & 32 & 0.82 & 333 \\ %
                %385Tib, 8Ki nodes
                Trinity~\cite{Trinity} (hypothetical w/ $CE_{Cielo}$)  &  89.6 &
                128 & 0.82 & 86.5\\   % 2 PiB, 16Knodes
                Summit~\cite{Summit} (hypothetical w/ $CE_{Cielo}$)  &  425.6 &
                608 & 0.82 & 17.3\\   % 10 PiB, 4Knodes
                Exascale (hypothetical w/ $CE_{Cielo}$) & 574 & 700 & 0.82 &
                15.4 \\% 16PiB, 16Ki nodes
                Exascale (hypothetical w/ $CE_{Cielo \times 10}$) & 5,740 & 700 &
                8.2 & 1.54 \\% 16PiB, 16Ki nodes
                Exascale (hypothetical w/ $CE_{median( Facebook )}$) & 75,600 & 700 & 108 &
                0.12 \\% 16PiB, 16Ki nodes
%               Exascale (hypothetical w/ $CE_{Blue Waters}$) & 
%               427 & 700 & 0.61 & 20.41  \\% 16PiB, 16Ki nodes
         \bottomrule
        \end{tabular}
        \vspace{.6em}
        \caption{ 
                Measured and hypothesized correctable error rates
        }
        \label{tab:CE_rate}
\end{table*}

