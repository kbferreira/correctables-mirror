
\section{Experiential Approach}
\label{sec:approach}

\subsection{APEI Error Injection}

As stated previously, this work is focused on the impacts of correctable errors.
These impacts occur at a number of different levels in the system.  To measure
these impacts we need a method of injecting these errors in a system to measure
the costs.  A number of methods exist to inject these types of errors on a
running system: from hardware-specific DRAM daughter cards that synthetically
flip memory cells within the DIMM device to methods that stress the memory
system in an effort to induce failures. 

In this work, we use the error injection table (EINJ) support provided as part
of the Advanced Configuration and Power Interface (ACPI)
specification~\cite{ACPISpec}.  EINJ provides a platform-independent interface
through which the platform OS can inject hardware errors to the platform without
requiring platform specific level software support. The primary goal of this
mechanism is to support testing of the OS error handling stack. Through this
capability the OS is able to implement a simple interface for diagnostic and
validation of RAS handling on the system.  EINJ is not supported on 
every production platform, it requires support from the host processor, OS, and
firmware/BIOS.

\begin{table}
\centering
\begin{tabular}{ c l }
\toprule
Error Type Value & Error Description \\
\midrule
 0x00000001 & Processor Correctable\\
 0x00000002 & Processor Uncorrectable non-fatal \\
 0x00000004 & Processor Uncorrectable fatal \\
        {\bf{0x00000008}} & {\bf{Memory Correctable}} \\
 0x00000010 & Memory Uncorrectable non-fatal \\
 0x00000020 & Memory Uncorrectable fatal \\
 0x00000040 & PCI Express Correctable \\
 0x00000080 & PCI Express Uncorrectable fatal \\
 0x00000100 & PCI Express Uncorrectable non-fatal \\
 0x00000200 & Platform Correctable \\
 0x00000400 & Platform Uncorrectable non-fatal \\
 0x00000800 & Platform Uncorrectable fatal \\
\bottomrule
\end{tabular}
\vspace{.6em}
\caption{
        Available error types defined in ACPI specification.  Highlighted value
        used in this current work 
}
\label{tab:einj}
\end{table}

The specification defines a number of different error types.  These types are
defined in \Cref{tab:einj}.  On our test linux platform, only the memory
correctable and memory uncorrectable error types are supported.  Injecting
errors through the EINJ table on linux is done through the sysfs filesystem
interface.  This injection interface allows a user to specifically the error type
and memory address for the error.

\subsection{Memory Failure Logging}

\kbf{The following paragraph is nearly identical to parallel submission,
change}

DRAM on typical modern systems is protected by an error-correcting
codes~(ECC).  When the memory controller detects a memory error, it attempts to
use the ECC to correct the error.  If it is able to correct the error, the
error is recorded as a \emph{correctable error}~(CE).  If it is unable to
correct the error, the error is recorded as a \emph{detected, uncorrectable
error}~(DUE).  Correctable errors are recorded in registers provided by the x86
Machine Check Architecture~(MCA)~\cite{AMD,IntelGuide}.  The contents of these
registers are polled periodically and written to the console log.
Uncorrectable errors are recorded in an event log after the node is rebooted
due to the occurrence of an uncorrected error.  For both correctable and
uncorrectable errors, detailed information about each error can be recorded.
This information includes the physical address where the error occurred and ECC
syndrome data that describes the cause of the error.  Decoding the recorded
information about each error allows us to identify the physical location of
each logged error, but this decoding process takes time, perturbing application
performance.

For correctable errors, there are two ways that the processor can be notified of
the error: software-based and firmware-based.  In the case of software-based
notification, a Corrected Machine Check Interrupt
(CMCI)~\cite{IntelGuide,Gottscho:2017:Measuring} is generated which records
the DRAM error and the time of its occurrence. In this case, it may be difficult
to determine the precise DRAM location of an error because of complexities related
to memory organization~\cite{Gottscho:2017:Measuring}.  As a result, mitigating
failures with memory page retirement~\cite{Tang:2006:Assessment} may not always
be possible with CMCI-based reporting.  With firmware-based notification, the
information recorded when the error occurs allows the physical address and the
specific DRAM device to be determined.  Firmware-based notification relies on the
Enhanced Machine Check Architecture (EMCA)~\cite{MCAEnhancements}.  While this
method allows for precise identification of the source of the error, it is very
expensive.  It requires the system to enter System Management Mode~(SMM) which halts
all forward progress while the memory configuration information is assembled and
passed to system software~\cite{Gottscho:2017:Measuring}. SMM mode is expensive
as it halts progress on \emph{all} cores on a node until the SMM mode is left.

To measure the system impacts of the memory decoding and logging overheads, we
use the \selfish~\cite{Hoefler:2010:Characterizing} system noise measurement
microbenchmark. \selfish tracks chunks of time taken away from the CPU for
system tasks (termed detours), by continuously reading the processor timestamp
counter (TSC)~\cite{IntelGuide}.  When the counter has reading has exceeded a
certain threshold~\footnote{In our case, 150 nanoseconds}, the time and duration
of this detour is recorded.

\subsection{Simulating Correctable Overheads}

In general, the communication structure of Message Passing Interface (MPI)
programs cannot be determined offline because message matches cannot be
established statically~\cite{bronevetsky2009communication}.  This makes
modeling application performance analytically challenging even if all
parameters of the application (e.g., the complete communication structure and
all relative inter-process timings) are known.  We therefore use a validated
discrete-event simulation framework to evaluate the impact of local
correctable error mitigation activities on the performance of real applications.
%for real applications via their message traces.

Our simulation-based approach models correctable error mitigation activities as
CPU detours: periods of time during which the CPU is taken from the application
and used to compute and commit checkpoint data.  This approach allows a level of
fidelity and control not always possible in implementation-based approaches. It
also allows us to examine simulated systems much larger than those generally
available.

Our simulation framework is based on the freely available
\LogGOPSim~\cite{Hoefler:2010:LogGOPSim} and the tool chain provided  by Levy et
al.~\cite{Levy2013UsingSimulation}.  \LogGOPSim uses the LogGOPS model, an
extension of the well-known LogP model~\cite{Culler:1993:LogP}, to account for
the temporal cost of communication events.  An application's communication
events are generated from traces of the application's execution.  These traces
contain the sequence of MPI operations invoked by each application process.
\LogGOPSim uses these traces to reproduce all communication dependencies,
including indirect dependencies between processes which do not communicate
directly.

\LogGOPSim can also extrapolate traces from small application runs; a trace
collected by running the application with $p$ processes can be extrapolated to
simulate performance of the application running with $k\cdot p$ processes. The
extrapolation produces exact communication patterns for MPI collective
operations and approximates point-to-point
communications~\cite{Hoefler:2010:LogGOPSim}.  The validation of \LogGOPSim and
its trace extrapolation features have been documented
previously~\cite{Hoefler:2010:LogGOPSim}, along with the simulators ability to
accurately predict application performance in the presence of performance
perturbations~\cite{Ferreira:2014:Understanding,Levy2013UsingSimulation,Hoefler:2010:Characterizing}

\begin{table}
\centering
\begin{tabular}{ l c }
\toprule
LogGOPS parameter & Cray XC40 \\
\midrule
\textcolor{red}{L}atency                & 1.8$\mu s$ \\
\textcolor{red}{o}verhead per message   & 12.4$\mu s$ \\
\textcolor{red}{g}ap per message        & 2.6$\mu s$  \\
\textcolor{red}{G}ap per byte           & 1$ns$     \\
\textcolor{red}{O}verhead per byte      & 0$ns$     \\
\textcolor{red}{S}: rendezvous threshold& 65,536 bytes \\
\bottomrule
\end{tabular}
\vspace{.6em}
\caption{
  LogGOPS parameters used in our study which roughly correspond to a Cray
  XC40 architectures.
}
\label{tab:logp}
\end{table}

\subsection{Simulation Setup and Reproducibility}

To generate the data presented in this paper, we collected execution traces for
128 node runs for each applications described in \Cref{tab:app_desc} system.  We
simulated the collected native traces~\footnote{All traces from non-export
controlled application can found online, details in \Cref{sec:appendix}} with
\LogGOPSim using parameters found in \Cref{tab:logp} which roughly correspond to
a Cray XC40 architecture, a modern leadership class system. We then verified
that the simulator accurately reproduces (within 6\%) the execution time on the
respective system.

We model correctable failures using the OS noise injection functionality of
\LogGOPSim.  Using the error injection interface described previously, we
characterize the cost of correctable logging and decoding under a number
different scenarios.  Using costs measure in this work as well as costs
detailed in previous works~\cite{Gottscho:2017:Measuring} along with previously
published DRAM correctable error
rates~\cite{Li10,Hwang12,Sridharan13,Bautista-Gomez:2016:Unprotected}, we create
OS \emph{traces}~\footnote{Correctable error noise traces are also available
online, details in \Cref{sec:appendix}} that simulate the cost of correctables
while running the application trace.  Therefore, processes experiencing a
correctable error will be appropriately delayed when injected along with any
communicating processes, as detailed in \Cref{fig:propagation}.

We examine the performance of a number of HPC workloads.  These workloads,
described in \Cref{tab:app_desc}, include three important DOE production
applications (LAMMPS, CTH, and SPARC), an important HPC benchmark (HPCG), a
proxy application (LULESH) from the Department of Energy's Exascale Co-Design
Center for Materials in Extreme Environments~(ExMatEx), a scientific code used
to study the behavior of subatomic particles~(MILC), and a
mini-application~(miniFE) from Sandia's Mantevo suite.  This is a diverse set of
workloads that captures a wide range of computational methods and application
behaviors.  It additionally captures a significant cross-section of the
scalable, high-performance applications that are run on current extreme-scale
systems as well as workloads that represent the computational patterns that are
expected to be run on future systems.  Lastly, we also use a number of MPI
collective microbenchnarks to examine collective algorithm impacts.  The
pseudocode for these microbenchmarks can be found in \Cref{alg:microbenchmark}.

\newcommand{\appDescWidth}{10.5cm}

\begin{table*}[ht!]
\centering
\begin{tabular}{@{}lc@{}}
\toprule
Application & Description \tabularnewline
\midrule
% NOTE: SNAP is not part of the current LAMMPS distribution
%LAMMPS & \parbox{\appDescWidth}{Large-scale Atomic/Molecular Massively Parallel Simulator (LAMMPS).
        LAMMPS & \parbox{\appDescWidth}{\tiny{A classical molecular dynamics simulator from Sandia National  
                                Laboratories~\cite{Plimpton:1995:Fast, LAMMPS_web}.  The data presented in                           
                                this paper are from experiments that use the Lennard-Jones (LAMMPS-lj)                               
                                potential that is included with the LAMMPS distribution.}}\\
  & \\                          
%LULESH & \parbox{\appDescWidth}{Livermore Unstructured Lagrangian Explicit Shock Hydrodynamics (LULESH).  
        LULESH & \parbox{\appDescWidth}{\tiny{A proxy application from the Department of Energy Exascale Co-Design Center
                                for Materials in Extreme Environments (ExMatEx).  LULESH approximates the
                                hydrodynamics equations discretely by partitioning the spatial problem domain
                                into a collection of volumetric elements defined by a
                                 mesh~\cite{LULESH_web}.}}\\
  & \\
        HPCG & \parbox{\appDescWidth}{\tiny{A benchmark that generates and solves a synthetic 3D sparse linear system using
                              a local symmetric Gauss-Seidel preconditioned conjugate gradient
                              method~\cite{HPCG_web}.}}\\
  & \\
        CTH & \parbox{\appDescWidth}{\tiny{A multi-material, large deformation, strong shock wave, solid mechanics
                             code~\cite{McGlaun:1990:CTH, Hertel:93:CTH} developed at Sandia National 
                             Laboratories.  The data presented in this paper are from experiments that use
                             an input that describes the simulation of the detonation of a conical explosive
                             charge (CTH-st).}}\\
  & \\
        MILC & \parbox{\appDescWidth}{\tiny{A large scale numerical simulation to study quantum chromodynamics~(QCD), the theory
                              of the strong interactions of subatomic physics~\cite{MILC_web}.}}\\
  & \\
        miniFE & \parbox{\appDescWidth}{\tiny{A proxy application that captures the key behaviors of unstructured implicit
                                finite element codes~\cite{Heroux09Mantevo}.}}\\
  & \\
        SPARC & \parbox{\appDescWidth}{\tiny{SPARC~\cite{Howard:2017:Sparc} is a next-generation compressible
        computational fluid dynamics (CFD) code being developed by Sandia National Laboratories
        as part of the NNSA's Advanced Technology Development and Mitigation (ATDM) subprogram.
        SPARC solves the Navier-Stokes and Reynolds-Averaged Navier-Stokes (RANS turbulence models)
        equations on structured and unstructured grids and is targeted towards the transonic flow
        regime to support gravity bomb analyses and the hypersonic flow regime to analyze re-entry
        vehicle analyses. In this work, the ``Generic Reentry Vehicle'' (GRV) input problem was
        used.}}\\

\bottomrule
\end{tabular}
\caption{Descriptions of the workloads used in evaluation.}
\label{tab:app_desc}
\end{table*}

\begin{figure}[ht!]
\centering
%\begin{minipage}[t]{0.90\textwidth}
\begin{algorithm}[H]
\caption*{\textbf{Collective operation microbenchmark}}\label{alg:collectives}
\begin{algorithmic}
%\State{interval\_duration $\in \lbrace 50ms, 500ms, 5s, 50s\rbrace$}
        \State{collective\_operation $\in \lbrace$ \texttt{Stencil}\\
                                          \hspace{2.35cm}\MPIAllreduce, \MPIAlltoall, \\ 
                                          \hspace{2.35cm}\MPIBcast, \MPIReduce$\rbrace$}
\State
\Procedure{collective\_micro}{collective\_operation}
\ForAll{intervals}
    \State \emph{execute} collective\_operation
    \State \emph{sleep} $100ms$
\EndFor
\EndProcedure
\end{algorithmic}
\end{algorithm}
%\end{minipage}
        \captionof{algorithm}{Pseudocode of collective operation microbenchmark.
        \kbf{Modify to match data}}
\label{alg:microbenchmark}
\end{figure}

\subsection{Simulated Correctable Error Rates}

\kbf{Add a discussion and justification here for rates we use} 

\begin{table}
\centering
\begin{tabular}{ c l }
\toprule
        System & Mean Error Rate (Hz) \\
\midrule
        Facebook Servers & Processor Correctable\\
 0x00000002 & Processor Uncorrectable non-fatal \\
 0x00000004 & Processor Uncorrectable fatal \\
        {\bf{0x00000008}} & {\bf{Memory Correctable}} \\
 0x00000010 & Memory Uncorrectable non-fatal \\
 0x00000020 & Memory Uncorrectable fatal \\
 0x00000040 & PCI Express Correctable \\
 0x00000080 & PCI Express Uncorrectable fatal \\
 0x00000100 & PCI Express Uncorrectable non-fatal \\
 0x00000200 & Platform Correctable \\
 0x00000400 & Platform Uncorrectable non-fatal \\
 0x00000800 & Platform Uncorrectable fatal \\
\bottomrule
\end{tabular}
\vspace{.6em}
\caption{
        Measured and hypothesized cortectable error rates
}
\label{tab:CE_rate}
\end{table}

